{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[50756]: Class AVFFrameReceiver is implemented in both /Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/av/.dylibs/libavdevice.60.3.100.dylib (0x309358760) and /Users/tt/miniforge3/envs/ds/lib/libavdevice.59.7.100.dylib (0x31c414778). One of the two will be used. Which one is undefined.\n",
      "objc[50756]: Class AVFAudioReceiver is implemented in both /Users/tt/miniforge3/envs/ds/lib/python3.8/site-packages/av/.dylibs/libavdevice.60.3.100.dylib (0x3093587b0) and /Users/tt/miniforge3/envs/ds/lib/libavdevice.59.7.100.dylib (0x31c4147c8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import moviepy.editor as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def mel_spectrogram(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    transformMel = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n",
    "                                                        n_mels=128,\n",
    "                                                        hop_length=256,\n",
    "                                                        n_fft=1024)\n",
    "    transformdB = torchaudio.transforms.AmplitudeToDB()\n",
    "    mel_spec = transformMel(waveform)\n",
    "    mel_spec = transformdB(mel_spec)\n",
    "    return mel_spec\n",
    "\n",
    "tmp = mel_spectrogram('./MELD_Data/train/dia0_utt0.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 비디오 파일에서 오디오를 추출하여 저장하는 함수\n",
    "def extract_audio_from_video(video_path, output_audio_path):\n",
    "    try:\n",
    "        # 비디오 파일에서 오디오 추출\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        video.audio.write_audiofile(output_audio_path, codec='pcm_s16le')\n",
    "        print(f\"Audio extracted and saved to: {output_audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {video_path}: {e}\")\n",
    "\n",
    "# MELD 데이터셋에서 비디오 파일들을 처리\n",
    "video_folder = '/content/train_splits'  \n",
    "output_folder = '/content/video_to_audio'  \n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 비디오 파일들 순회\n",
    "for root, dirs, files in os.walk(video_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4'):  # 파일 확장자가 .mp4인 경우에만 처리\n",
    "            video_path = os.path.join(root, file)\n",
    "            output_audio_path = os.path.join(output_folder, file.replace('.mp4', '.wav'))\n",
    "            extract_audio_from_video(video_path, output_audio_path)\n",
    "\n",
    "\n",
    "\n",
    "def mel_spectrogram(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    transform = torchaudio.transforms.Compose([\n",
    "        torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mels=128,\n",
    "            hop_length=256,\n",
    "            n_fft=1024),\n",
    "        torchaudio.transforms.AmplitudeToDB()\n",
    "    ])\n",
    "    mel_spec = transform(waveform)\n",
    "\n",
    "    # 멜 스펙트로그램 시각화 및 저장\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(log_mel_spec[0].numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "    plt.title('Log-Mel Spectrogram')\n",
    "    plt.ylabel('Mel Frequency')\n",
    "    plt.xlabel('Time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.savefig(output_image_path)\n",
    "    plt.close()\n",
    "    print(f\"Mel spectrogram saved to: {output_image_path}\")\n",
    "\n",
    "# 오디오 파일들이 저장된 폴더와 멜 스펙트로그램 이미지를 저장할 폴더 설정\n",
    "audio_folder = '/content/video_to_audio'  \n",
    "output_folder = '/content/mel_spectrogram_image'  # 멜 스펙트로그램 이미지를 저장할 폴더 경로\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 오디오 파일들 순회 및 멜 스펙트로그램 변환\n",
    "for root, dirs, files in os.walk(audio_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):  \n",
    "            audio_path = os.path.join(root, file)\n",
    "            output_image_path = os.path.join(output_folder, file.replace('.wav', '.png'))\n",
    "            convert_audio_to_mel_spectrogram(audio_path, output_image_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ResNet을 사용하여 이미지 특징 추출\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# 공통 Transformer 백본 정의\n",
    "class CommonTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(CommonTransformer, self).__init__()\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=input_dim,\n",
    "            nhead=8,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(2).permute(2, 0, 1)  # Transformer expects (S, N, E)\n",
    "        output = self.transformer(x, x)\n",
    "        return output.permute(1, 0, 2)  # Back to (N, S, E)\n",
    "\n",
    "# OmniVec 모델 정의\n",
    "class OmniVecModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OmniVecModel, self).__init__()\n",
    "        self.image_encoder = ResNetEncoder()\n",
    "        self.common_transformer = CommonTransformer(input_dim=2048, hidden_dim=2048, num_layers=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.image_encoder(x)\n",
    "        features = self.common_transformer(x)\n",
    "        return features\n",
    "\n",
    "# 모델 생성\n",
    "model = OmniVecModel()\n",
    "\n",
    "# 이미지 전처리 함수 정의\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# 멜 스펙트로그램 이미지들이 저장된 폴더 설정\n",
    "image_folder = '/content/mel_spectrogram_image' \n",
    "\n",
    "# 이미지 파일들 순회 및 특징 추출\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):  # 파일 확장자가 .png인 경우에만 처리\n",
    "            image_path = os.path.join(root, file)\n",
    "            image_tensor = preprocess_image(image_path)\n",
    "            \n",
    "            # 모델을 통해 특징 추출\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                features = model(image_tensor)\n",
    "                print(f\"Extracted Features Shape for {file}: {features.shape}\")\n",
    "                print(f\"Extracted Features for {file}: {features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
